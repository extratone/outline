<!DOCTYPE html><html lang="en"><head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no, viewport-fit=cover"> <link crossorigin="true" href="https://outline-prod.imgix.net" rel="preconnect"><link crossorigin="true" href="https://d1z2jf7jlzjs58.cloudfront.net" rel="preconnect"><link crossorigin="true" href="https://srv-2019-01-31-21.pixel.parsely.com" rel="preconnect"><link crossorigin="true" href="https://www.google-analytics.com" rel="preconnect"><link crossorigin="true" href="https://pixel.quantserve.com" rel="preconnect"><link crossorigin="true" href="https://rules.quantcount.com" rel="preconnect"><link crossorigin="true" href="https://sb.scorecardresearch.com" rel="preconnect"><link crossorigin="true" href="https://secure.quantserve.com" rel="preconnect"> <link href="/css/content.71401fe3f321ef57af9c.css" rel="stylesheet" type="text/css"> <link rel="icon" type="image/png" href="/images/favicon/pink/favicon-194x194.89224724481dc8d0efa135fcc4aef1dd.png" sizes="194x194"> <link rel="icon" type="image/png" href="/images/favicon/pink/favicon-32x32.51d2a9128c35821eae506c336486e97a.png" sizes="32x32"> <link rel="icon" type="image/png" href="/images/favicon/pink/favicon-16x16.1b624a5e4111ff9d82623870b8230534.png" sizes="16x16"> <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.6abc580137cc97a42adde882e1ba60ec.png"> <link rel="mask-icon" href="/images/safari-pinned-tab.be282935e74cdc2f0462721ddf7e0139.svg" color="#5bbad5"> <meta name="theme-color" content="#ffffff"> <title>The fight against racist algorithms | The Outline</title> <link rel="canonical" href="https://theoutline.com/post/1571/the-fight-against-racist-algorithms"> <meta name="description" content="Can we teach our machines to unlearn racism?"> <meta name="post_id" content="1571"> <meta name="parsely-metadata" content="{&quot;type&quot;:&quot;post&quot;,&quot;post_type&quot;:&quot;post&quot;,&quot;post_id&quot;:1571}"> <meta property="og:type" content="article"> <meta property="og:site_name" content="The Outline"> <meta property="fb:app_id" content="103730476786039"> <meta property="fb:pages" content="527050847445390"> <meta property="article:publisher" content="https://www.facebook.com/outline"> <meta property="og:url" content="https://theoutline.com/post/1571/the-fight-against-racist-algorithms"> <meta property="og:title" content="The fight against racist algorithms"> <meta property="og:description" content="Can we teach our machines to unlearn racism?"> <meta property="og:image" content="https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?auto=format&amp;q=60&amp;w=1280&amp;s=b9d3d1c897a20f2a163a82272e960731"> <meta property="twitter:card" content="summary_large_image"> <meta property="twitter:site" content="@outline"> <meta property="twitter:title" content="The fight against racist algorithms"> <meta property="twitter:description" content="Can we teach our machines to unlearn racism?"> <meta property="twitter:image:src" content="https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?auto=format&amp;q=60&amp;w=1280&amp;s=b9d3d1c897a20f2a163a82272e960731"> <meta property="article:author" content="Tolulope Edionwe"> <script type="application/ld+json"> {"url":"https://theoutline.com/post/1571/the-fight-against-racist-algorithms","thumbnailUrl":"https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?auto=format&q=60&w=1280&s=b9d3d1c897a20f2a163a82272e960731","publisher":{"name":"The Outline","logo":"/images/logo.svg","@type":"Organization"},"keywords":["The Future"],"image":"https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?auto=format&q=60&w=1280&s=b9d3d1c897a20f2a163a82272e960731","headline":"The fight against racist algorithms","description":"Can we teach our machines to unlearn racism?","datePublished":"2017-05-24T12:51:00.000000Z","dateCreated":"2017-05-24T12:51:00.000000Z","creator":["Tolulope Edionwe"],"author":["Tolulope Edionwe"],"articleSection":"The Future","@type":"NewsArticle","@context":"http://schema.org"}</script> <script id="path-state" type="application/json">{&quot;zipper_id&quot;:&quot;jsjwedyr&quot;,&quot;type&quot;:&quot;post&quot;,&quot;sensitive&quot;:false,&quot;path&quot;:[{&quot;url&quot;:&quot;https://theoutline.com/post/1571/the-fight-against-racist-algorithms&quot;,&quot;type&quot;:&quot;standard&quot;,&quot;title&quot;:&quot;The fight against racist algorithms&quot;,&quot;styles&quot;:&quot;\n[data-post-id=\&quot;1571\&quot;] {\n --scheme-color-a: #04284A;\n--scheme-color-a__r: 4;\n--scheme-color-a__g: 40;\n--scheme-color-a__b: 74;\n--scheme-color-a__h-squiggle: url(\&quot;/svg/sq/h?a=4&amp;anim=true&amp;c=04284A&amp;f=5\&quot;);\n--scheme-color-b: #CE2C36;\n--scheme-color-b__r: 206;\n--scheme-color-b__g: 44;\n--scheme-color-b__b: 54;\n--scheme-color-b__h-squiggle: url(\&quot;/svg/sq/h?a=4&amp;anim=true&amp;c=CE2C36&amp;f=5\&quot;);\n--scheme-color-c: #FFE600;\n--scheme-color-c__r: 255;\n--scheme-color-c__g: 230;\n--scheme-color-c__b: 0;\n--scheme-color-c__h-squiggle: url(\&quot;/svg/sq/h?a=4&amp;anim=true&amp;c=FFE600&amp;f=5\&quot;);\n--scheme-color-d: #FFFFFF;\n--scheme-color-d__r: 255;\n--scheme-color-d__g: 255;\n--scheme-color-d__b: 255;\n--scheme-color-d__h-squiggle: url(\&quot;/svg/sq/h?a=4&amp;anim=true&amp;c=FFFFFF&amp;f=5\&quot;);\n\n}\n&quot;,&quot;sensitive&quot;:false,&quot;path&quot;:&quot;/post/1571/the-fight-against-racist-algorithms&quot;,&quot;parent_id&quot;:1571,&quot;id&quot;:1571,&quot;html&quot;:null,&quot;description&quot;:&quot;Can we teach our machines to unlearn racism?&quot;,&quot;content_type&quot;:&quot;post&quot;}],&quot;location&quot;:0,&quot;hydrationLocation&quot;:0,&quot;geo_location&quot;:&quot;unknown&quot;,&quot;features&quot;:{},&quot;enabled&quot;:true}</script></head> <body class="app "> <main id="main" class="main"> <path-root class="path ui-path-scroll-js"> <div class="path__progress" data-index="0"> <div class="path__progress__wrapper"> <span class="path__progress__bar"></span> </div> </div> <path-plane class="path__plane"> <style type="text/css"> [data-post-id="1571"] { --scheme-color-a: #04284A; --scheme-color-a__r: 4; --scheme-color-a__g: 40; --scheme-color-a__b: 74; --scheme-color-a__h-squiggle: url("/svg/sq/h/a-4/anim-true/c-04284A/f-5.svg"); --scheme-color-b: #CE2C36; --scheme-color-b__r: 206; --scheme-color-b__g: 44; --scheme-color-b__b: 54; --scheme-color-b__h-squiggle: url("/svg/sq/h/a-4/anim-true/c-CE2C36/f-5.svg"); --scheme-color-c: #FFE600; --scheme-color-c__r: 255; --scheme-color-c__g: 230; --scheme-color-c__b: 0; --scheme-color-c__h-squiggle: url("/svg/sq/h/a-4/anim-true/c-FFE600/f-5.svg"); --scheme-color-d: #FFFFFF; --scheme-color-d__r: 255; --scheme-color-d__g: 255; --scheme-color-d__b: 255; --scheme-color-d__h-squiggle: url("/svg/sq/h/a-4/anim-true/c-FFFFFF/f-5.svg"); } </style> <path-element class="path__element" data-post-id="1571" data-post-type="standard"> <div class="path__element__content"> <path-page class="page post post--layout-2 post--color-scheme-2 post--text-style-2 post--embed-style-2 color_filter--red-blue color_family--standard card_type--outline" data-type="standard" data-color-filter="red-blue" data-truncated> <div class="post__lead"> <header class="post__header hide-lt-desktop"> <div class="post__eyebrow">Code bias</div> <h1 class="post__title">The fight against racist algorithms</h1> <h2 class="post__dek">Can we teach our machines to unlearn racism?</h2> </header> <div class="post__card"> <div class="card background_effect--none color_filter--red-blue filter_type--duotone text_color--color text_size--xsmall desktop_text_size--medium card_type--outline" data-color-filter="red-blue"><div class="outline-card outline-card--1 outline-card--1--3-outlines"> <div class="outline-card__bg ui-animate-in--bg" data-color-filter="red-blue"> <div class="card__bg__image"> <img alt src="https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?s=df8659c8fa1deae8b0d98d09ddef0458?auto=format&amp;q=60&amp;w=1280&amp;s=b09877e36aecb9d488573065ad4671a4&amp;duotone=04284A,CE2C36" srcset="https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?s=df8659c8fa1deae8b0d98d09ddef0458?auto=format&amp;q=60&amp;w=750&amp;s=3390f3f5faacd56bf2217f36b542f1a4&amp;duotone=04284A,CE2C36 750w, https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?s=df8659c8fa1deae8b0d98d09ddef0458?auto=format&amp;q=60&amp;w=1280&amp;s=b09877e36aecb9d488573065ad4671a4&amp;duotone=04284A,CE2C36 1280w, https://outline-prod.imgix.net/20170523-8E5vleXPouFQ1tPLMOdH?s=df8659c8fa1deae8b0d98d09ddef0458?auto=format&amp;q=60&amp;w=3000&amp;s=4732e43142f406465763632d8f7bc07e&amp;duotone=04284A,CE2C36 3000w"></div> </div> <div class="outline-card__content ui-animate-in--content"> <p class="outline-card__eyebrow ui-transition-in--1 ui-animate-in--1">Code bias</p> <div class="outline-card__body"> <div class="outline-card__line"></div> <div class="outline-card__title-and-outlines"> <h3 class="outline-card__title ui-transition-in--1 ui-animate-in--1"><span class="text">The AI field has a big problem</span></h3> <div class="outline-card__outlines"> <div class="outline-card__outline ui-transition-in--2 ui-animate-in--2"> <span class="text">Machine learning techniques keep creating racist algorithms</span> </div> <div class="outline-card__outline ui-transition-in--2 ui-animate-in--2"> <span class="text">Researchers are scrambling to stop the trend, but it is extremely complex</span> </div> <div class="outline-card__outline ui-transition-in--2 ui-animate-in--2"> <span class="text">The good news is that there are ways to prevent and un-teach algorithmic bias</span> </div> </div> </div> <div class="outline-card__line"></div> </div> </div> </div> <button class="card__cta card__cta--arrow" aria-hidden="true"> <span class="icon-arrowdown"></span> </button> </div> <div class="post__card__share-container"> <div class="post__card__share" data-button-count="5"> <button class="navigation__menu__item post__card__share__toggle" type="button" aria-hidden="true"> <span class="icon icon-share"></span> </button> <div class="post__card__share__outlets"> <a class="post__card__share__outlet" data-network="facebook" href="https://www.facebook.com/dialog/share?app_id=103730476786039&amp;display=page&amp;href=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms" target="_blank" rel="noopener" aria-hidden="true"><span class="icon-facebook"></span></a> <a class="post__card__share__outlet" data-network="twitter" href="https://twitter.com/intent/tweet?text=The+fight+against+racist+algorithms&amp;url=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&amp;via=outline" target="_blank" rel="noopener" aria-hidden="true"><span class="icon-twitter"></span></a> <a class="post__card__share__outlet" data-network="flipboard" href="https://share.flipboard.com/bookmarklet/popout?title=The+fight+against+racist+algorithms&amp;url=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&amp;utm_campaign=publisher&amp;utm_medium=article-share&amp;utm_source=theoutline" target="_blank" rel="noopener" aria-hidden="true"><span class="icon-flipboard"></span></a> <a class="post__card__share__outlet" data-network="email" href="mailto:?subject=The%20fight%20against%20racist%20algorithms&amp;body=You%20should%20really%20stop%20what%20you&apos;re%20doing%20and%20read%20this%20now:%0A%0AThe%20fight%20against%20racist%20algorithms%0A%0ACan%20we%20teach%20our%20machines%20to%20unlearn%20racism?%0A%0Ahttps://theoutline.com/post/1571/the-fight-against-racist-algorithms" aria-hidden="true"><span class="icon-mail"></span></a> <div class="post__card__share__outlet post__card__share__outlet--description" data-network="description"> <span class="icon icon-info"></span> <div class="post__card__share__description">Qilai Shen / Bloomberg via Getty Images</div> </div> </div> </div> </div> </div> </div> <div class="post__content page__content"> <header class="post__header hide-gt-desktop"> <div class="post__eyebrow">Code bias</div> <p class="post__title">The fight against racist algorithms</p> <p class="post__dek">Can we teach our machines to unlearn racism?</p> <div class="post__share"> <div class="post__share__outlets"> <a class="post__share__outlet" data-network="facebook" href="https://www.facebook.com/dialog/share?app_id=103730476786039&amp;display=page&amp;href=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms" target="_blank" rel="noopener" aria-label="Share on Facebook"><span class="icon-facebook"></span></a> <a class="post__share__outlet" data-network="twitter" href="https://twitter.com/intent/tweet?text=The+fight+against+racist+algorithms&amp;url=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&amp;via=outline" target="_blank" rel="noopener" aria-label="Share on Twitter"><span class="icon-twitter"></span></a> <a class="post__share__outlet" data-network="flipboard" href="https://share.flipboard.com/bookmarklet/popout?title=The+fight+against+racist+algorithms&amp;url=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&amp;utm_campaign=publisher&amp;utm_medium=article-share&amp;utm_source=theoutline" target="_blank" rel="noopener" aria-label="Share on Flipboard"><span class="icon-flipboard"></span></a> <a class="post__share__outlet" data-network="email" href="mailto:?subject=The%20fight%20against%20racist%20algorithms&amp;body=You%20should%20really%20stop%20what%20you&apos;re%20doing%20and%20read%20this%20now:%0A%0AThe%20fight%20against%20racist%20algorithms%0A%0ACan%20we%20teach%20our%20machines%20to%20unlearn%20racism?%0A%0Ahttps://theoutline.com/post/1571/the-fight-against-racist-algorithms" aria-label="Share via email"><span class="icon-mail"></span></a> </div> </div> </header> <div class="post__article"> <article class="post__wrapper"> <div class="post__meta"> <span class="post__authors"><a class="post__linked-author" href="/contributor/21/tolulope-edionwe">Tolulope Edionwe</a></span> <date class="post__date post__date--published">May&#x2014;24&#x2014;2017 08:51AM EST</date> <div class="post__share"> <div class="post__share__outlets"> <a class="post__share__outlet" data-network="facebook" href="https://www.facebook.com/dialog/share?app_id=103730476786039&amp;display=page&amp;href=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms" target="_blank" rel="noopener" aria-label="Share on Facebook"><span class="icon-facebook"></span></a> <a class="post__share__outlet" data-network="twitter" href="https://twitter.com/intent/tweet?text=The+fight+against+racist+algorithms&amp;url=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&amp;via=outline" target="_blank" rel="noopener" aria-label="Share on Twitter"><span class="icon-twitter"></span></a> <a class="post__share__outlet" data-network="flipboard" href="https://share.flipboard.com/bookmarklet/popout?title=The+fight+against+racist+algorithms&amp;url=https%3A%2F%2Ftheoutline.com%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&amp;utm_campaign=publisher&amp;utm_medium=article-share&amp;utm_source=theoutline" target="_blank" rel="noopener" aria-label="Share on Flipboard"><span class="icon-flipboard"></span></a> <a class="post__share__outlet" data-network="email" href="mailto:?subject=The%20fight%20against%20racist%20algorithms&amp;body=You%20should%20really%20stop%20what%20you&apos;re%20doing%20and%20read%20this%20now:%0A%0AThe%20fight%20against%20racist%20algorithms%0A%0ACan%20we%20teach%20our%20machines%20to%20unlearn%20racism?%0A%0Ahttps://theoutline.com/post/1571/the-fight-against-racist-algorithms" aria-label="Share via email"><span class="icon-mail"></span></a> </div> </div> </div> <div class="post__body"> <p>Algorithms trained on massive piles of real-world data are often interchangeably and confusingly referred to as artificial intelligence, neural networks, and machine learning, as we all figure out how to navigate this new frontier of computing. Whatever they&#x2019;re called, they are ubiquitous.</p><p>These algorithms make invisible choices that affect everything from your daily perusal of YouTube to the sentencing of convicted criminals, and that ubiquity means that when these algorithms don&#x2019;t work correctly, they reproduce problems on an enormous scale. Researchers are now scrambling to figure out how to benefit from the powers of artificial intelligence without replicating human flaws, particularly biases such as sexism and racism.</p><p>But how do you help an algorithm unlearn racism? We&#x2019;ve written before about how bias gets unwittingly baked into algorithms. In April, it was discovered that the viral app FaceApp, which promised to &#x201C;transform your face using artificial intelligence,&#x201D; was <a href="https://theoutline.com/post/1439/machine-learning-is-racist-because-the-internet-is-racist">racist</a>. The app let users upload a photo and then modify it with various filters, including &#x201C;old,&#x201D; &#x201C;young,&#x201D; and &#x201C;hot.&#x201D; The underlying algorithm was trained through exposure to relevant examples of the same type of data over and over, in a process called machine learning. In this case, that meant feeding it likely thousands of photos of faces so that it could learn to recognize what a face was.</p><div class="z9" data-id="ur1Uyd0Q"></div><p>Unfortunately, this set of face photos was apparently mostly white, or else it was trained using data that reflected a preference for white features. This meant that a filter designed to make your face look &#x201C;hot&#x201D; translated to lighter skin, smaller noses, and rounder eyes.</p><p>The company behind the app, Wireless Lab, later removed the feature and apologized, blaming it all on the pitfalls of machine learning and pledging to correct the problem. But teaching an algorithm to not be racist is not easy. When <em>The Outline</em> reached out to Wireless Lab almost a month later, CEO Yaroslav Goncharov said it wasn&#x2019;t ready to release a feature that could compute hotness for all races. &#x201C;We don&apos;t have any updates yet,&#x201D; he said in an email. &#x201C;It is quite a time-consuming process.&#x201D;</p><blockquote class="pullquote pullquote--aside" data-hash="46973990"><span>Engineers don&#x2019;t totally understand how their own algorithms work</span></blockquote><div class="z9" data-id="ylanPIyR"></div><p>There are many other examples of algorithmic bias, where algorithms help propagate inequity. A translation tool produced female associations with family and male associations with career, while Google&#x2019;s photo tagging service mistakenly identified black photo subjects as gorillas.</p><p>Often these types of mistakes aren&#x2019;t due to an actual computing error or an evil cackling data scientist behind a partition. They occur when the algorithm is trained on data that doesn&#x2019;t represent a population well enough, or when the algorithm is irresponsibly designed to optimize a singular type of decision.</p><p>The truth is that, in the brave new era of machine learning, engineers <a href="https://theoutline.com/post/1228/when-machines-go-rogue">don&#x2019;t totally understand how their own algorithms work</a>. They create the conditions for learning, input data, and wait to see what the machine comes up with. What happens in between is a black box.</p><div class="z9" data-id="3lU4tXXG"></div><p>Preventing or correcting bias can seem impossible considering it works in the obscure subconscious of both humans and computers, but data scientists have been working on solving this problem for a while. The <a href="http://www.fatml.org/">Fairness, Accountability, and Transparency in Machine Learning conference</a>, or FAT/ML, held annually since 2014, brings together researchers working towards fairer guidelines and functionality for algorithms.</p><h2 class="h2">Prevention</h2><p>One of the main tactics in the fight against algorithmic bias is to clean up the data before it&#x2019;s even introduced into the system.</p><div class="z9" data-id="ZL68M7tH"></div><p>The most obvious correction is to ensure the data is representative. If it&#x2019;s faces, include all races and ages. If it&#x2019;s dogs, include all breeds. If it&#x2019;s language, include colloquial sources like Facebook posts along with formal documents like those published by the U.N., a popular machine learning resource since the documents are often translated into multiple languages.</p><p>Teaching data scientists to prepare their data more carefully is an important step towards preventing unfair results, said Suresh Venkatasubramanian, one of the FAT/ML conference organizers, as well as an associate professor in the School of Computing at the University of Utah and a member of the board of directors for ACLU&#x2019;s Utah branch.</p><blockquote class="pullquote pullquote--full" data-hash="40189375"><span>&#x201C;The challenge is still to get all of this to percolate back into the industry.&#x201D;</span></blockquote><div class="z9" data-id="sODd8qEe"></div><p>&#x201C;A lot of the problems that came up in the bad uses of machine learning can be attributed to people just not thinking through the results,&#x201D; he told <em>The Outline</em>.</p><p>That includes imagining the consequences of their choices, he said, and the larger context in which the results are going to be used. If you were designing a predictive hiring algorithm for deciding which job applicants would be most likely to succeed for example, and your training data was mostly made up of young white women, considering the broader social context of the algorithm decisions might include recognizing and taking steps to counter further homogeneity in your hiring practice.</p><p>Several research teams have constructed preprocessing methods for data sets that minimize disparate impact while maintaining relative accuracy. These equation-based methods include assigning more weight to underrepresented populations within the data set and duplicating data points in order to make up for underrepresentation.</p><div class="z9" data-id="EgDTCLZl"></div><h2 class="h2">Reverse-engineering bias</h2><p>The other main anti-bias strategy takes into account the fact that many machine-learned algorithms are opaque, whether for proprietary reasons or by deliberate design. In these black box algorithms, only the input and outputs are available while the actual implementation process is not discoverable, even to the original engineers.</p><p>In order to deduce whether or not such an algorithm is discriminatory, scientists can assess the algorithm output&#x2019;s dependence on different input data categories. If the output changes drastically in response to an input value being changed, then it becomes clear that that input category factors in considerably to how the algorithm produces output. And if that category is an attribute which is undesired as a contributing factor to the output (for example, <a href="http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html">race in regards to predicting recidivism rates</a>), then this provides grounds for re-examination of the algorithm.</p><p>To this end, institutions of data computing have begun to call for more transparent algorithms. The Association for Computing Machinery released a list of <a href="https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf">&#x201C;Principles for Algorithmic Transparency and Accountability&#x201D;</a> earlier this year, and the Institute of Electronic and Electrical Engineers is working on <a href="https://standards.ieee.org/develop/project/7003.html">a set of guidelines</a> of their own.</p><h2 class="h2">Continued improvements</h2><p>Suchana Seth, a data scientist and Ford-Mozilla Open Web Fellow at the Data &amp; Society research institute, is publishing a technical report later this year to make the case for algorithmic fairness even clearer to the larger data science community, and hopefully, to key players in the commercial field.</p><p>&#x201C;The challenge is still to get all of this to percolate back into the industry,&#x201D; she told <em>The Outline.</em> While big name companies like Microsoft and Google have installed anti-bias measures in the form of ethics boards, at many other smaller companies the responsibility for fairness rests solely upon the engineers, who aren&#x2019;t necessarily considering such matters.</p><p>By speaking to the scientists who are designing the systems, Seth hopes to bypass the bureaucracy and impress the need for preemptive considerations regarding fairness directly onto the source.</p><p>&#x201C;Even if we&#x2019;re not able to remove bias completely, we might at least be able to specify the extent to which we think there might be bias, or the extent to which we might be able to counter that bias,&#x201D; she said.</p><p>It&#x2019;s hard to overstate the significance of this effort. Structural inequality happens because government, corporate, and cultural institutions are predisposed to reward powerful groups and disenfranchise weak ones. If we aren&#x2019;t careful, algorithms will do the same thing.</p> </div> </article> <div class="post-micronative-footer"></div> <div class="post-footer"></div> </div> </div> </path-page> </div> </path-element> </path-plane> </path-root> </main> <div class="navigation"> <nav class="navigation__menu"> <a class="navigation__menu__item navigation__menu__item--logo" href="/" aria-label="Back to homepage"> <span class="icon icon-logo"></span> </a> <button class="navigation__menu__item navigation__menu__item--hamburger" type="button" aria-label="Open menu"> <span class="icon icon-menu"></span> </button> </nav> <div class="menu"> <button type="button" class="menu__close-button" aria-label="Close menu"> <span class="icon icon-close"></span> </button> <div class="menu__wrapper"> <h1 class="logo menu__logo" data-color="black"> <a class="logo__link menu__logo__link" href="/"> <span>The Outline</span> </a> </h1> <div class="menu__links"> <div class="menu__outmojis__wrapper"> <a class="menu__link" href="/topic/recent"> Recent </a> <a class="menu__link" href="/topic/power"> Power </a> <a class="menu__link" href="/topic/culture"> Culture </a> <a class="menu__link" href="/topic/future"> Future </a> <div class="menu__outmojis"> <div class="menu__outmojis__set" data-set="1"></div> <div class="menu__outmojis__set" data-set="2"></div> </div> </div> </div> <footer class="menu__footer"> <div class="menu__social"> <a class="menu__social__link" href="https://www.facebook.com/outline" target="_blank" rel="noopener" aria-hidden="true"> <span class="icon icon-facebook"></span> </a> <a class="menu__social__link" href="https://www.twitter.com/outline" target="_blank" rel="noopener" aria-hidden="true"> <span class="icon icon-twitter"></span> </a> <a class="menu__social__link" href="https://www.instagram.com/outline" target="_blank" rel="noopener" aria-hidden="true"> <span class="icon icon-instagram"></span> </a> <a class="menu__social__link" href="https://www.youtube.com/outline?sub_confirmation=1" target="_blank" rel="noopener" aria-hidden="true"> <span class="icon icon-youtube"></span> </a> <a class="menu__social__link" href="https://flipboard.com/@TheOutline?utm_campaign=tools&amp;utm_medium=follow&amp;utm_source=theoutline" target="_blank" rel="noopener" aria-hidden="true"> <span class="icon icon-flipboard"></span> </a> </div> <div class="menu__footer__links"> <a class="menu__footer__link" href="/about" target="_blank" rel="noopener" aria-hidden="true"> About </a> <a class="menu__footer__link" href="https://www.bustle.com/info/privacy" target="_blank" rel="noopener" aria-hidden="true"> Legal </a> <a class="menu__footer__link" href="https://jobs.lever.co/bustle" target="_blank" rel="noopener" aria-hidden="true"> Jobs </a> <a class="menu__footer__link" href="/tips" target="_blank" rel="noopener" aria-hidden="true"> Got A Tip? </a> </div> <span id="secret-code"></span> </footer> </div> </div> </div> <script> window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', "UA-81610258-1", 'auto'); ga('set', 'transport', 'beacon'); </script> <div id="parsely-root" style="display: none"> <span id="parsely-cfg" data-parsely-site="theoutline.com"></span> </div> <script> window.parselyPreload = { eventQueue: [], loaded: false }; window.PARSELY = { autotrack: false, onload: function() { parselyPreload.loaded = true; for (var i = 0; i < parselyPreload.eventQueue.length; i++) { window.PARSELY.beacon.trackPageView(parselyPreload.eventQueue[i]); } } }; </script> <script src="/js/vendor.956ecc2e1e50274f589c.js" type="text/javascript"></script><script src="/js/content.ed82e3dbe50552994f83.js" type="text/javascript"></script> <script> window.addEventListener("load", function() { var scripts = [ "https://www.google-analytics.com/analytics.js", "https://d1z2jf7jlzjs58.cloudfront.net/p.js" ]; setTimeout(function() { scripts.forEach(function(url) { var script = document.createElement("script"); script.src = url; script.async = true; script.defer = true; document.body.appendChild(script); }); }, 0); var img = new Image(); img.src = "https://d2ipj36xbzyufb.cloudfront.net/p.gif?host=theoutline.com&path=%2Fpost%2F1571%2Fthe-fight-against-racist-algorithms&referrer_domain=direct"; }); </script> <script> var _comscore = _comscore || []; _comscore.push({ c1: "2", c2: "27815420" }); </script> <noscript> <img src="https://sb.scorecardresearch.com/p?c1=2&c2=27815420&cv=2.0&cj=1" /> </noscript> <script> window.addEventListener("load", function() { var url = "https://sb.scorecardresearch.com/beacon.js"; setTimeout(function() { var script = document.createElement("script"); script.src = url; script.async = true; script.defer = true; document.body.appendChild(script); }, 0); }); </script> <script type="text/javascript"> var _qevents = _qevents || []; _qevents.push({ qacct:"p-xPmcrFNGfHkBg" }); </script> <noscript> <div style="display:none;"> <img src="https://pixel.quantserve.com/pixel/p-xPmcrFNGfHkBg.gif" border="0" height="1" width="1" alt="Quantcast"/> </div> </noscript> <script> window.addEventListener("load", function() { var url = "https://secure.quantserve.com/quant.js"; setTimeout(function() { var script = document.createElement("script"); script.src = url; script.async = true; script.defer = true; document.body.appendChild(script); }, 0); }); </script> </body></html>